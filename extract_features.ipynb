{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718d0c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Add baseline directory to path to import helper functions\n",
    "sys.path.append('baseline')\n",
    "from baseline.extract_metric import extract_metric_values, extract_multiple_metrics\n",
    "from utils.run_cmd import run_command, relative\n",
    "from utils.mrtrix import create_mask, create_response, create_fod, create_peaks, create_white_matter_mask\n",
    "from utils.tractseg import run_tractseg\n",
    "from utils.scilpy import run_scilpy_dti, estimate_frf, extract_fodf_metrics\n",
    "from utils.dwi_data import get_subjects, find_dwi_files\n",
    "from utils.fslstats import bundle_metrics\n",
    "from utils.fodf import compute_fodf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda97c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables - using Path objects\n",
    "# Path to ds003416 prequal derivatives (resolve to absolute path)\n",
    "dataset_root = Path(\"ds003416/derivatives/prequal-v1.0.0\").resolve()\n",
    "output_dir = Path(\"output\").resolve()\n",
    "tmp_dir = Path(\"tmp\").resolve()  # Use local tmp directory instead of /tmp\n",
    "\n",
    "# Output directory for intermediate files\n",
    "tractseg_output_dir = tmp_dir / \"tractseg_fa_output\"\n",
    "\n",
    "# Optionally filter specific subjects/sessions (set to None to process all)\n",
    "subjects_to_process = None  # Process all subjects\n",
    "# subjects_to_process = [\"sub-cIIIs01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863e7d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BeyondFA baseline on ds003416 prequal derivatives...\n",
      "\n",
      "Dataset root: ds003416/derivatives/prequal-v1.0.0\n",
      "Found 97 subjects\n",
      "Output directory: output\n",
      "Temporary directory: tmp\n",
      "Found 1134 DWI file(s)\n",
      "Verified 1134 existing DWI file(s)\n",
      "  - ds003416/.git/annex/objects/W3/Px/MD5E-s163573851--082d3a6c8a32dd850497d23929a005b1.nii.gz/MD5E-s163573851--082d3a6c8a32dd850497d23929a005b1.nii.gz\n",
      "  - ds003416/.git/annex/objects/J1/2g/MD5E-s10013617--ca95bc9e500c771c65cd0f12cead65f1.nii.gz/MD5E-s10013617--ca95bc9e500c771c65cd0f12cead65f1.nii.gz\n",
      "  - ds003416/.git/annex/objects/v9/P2/MD5E-s118401266--075e7b8b8bdd0e8c52f485ec6b3c6244.nii.gz/MD5E-s118401266--075e7b8b8bdd0e8c52f485ec6b3c6244.nii.gz\n",
      "  - ds003416/.git/annex/objects/2q/zv/MD5E-s10092523--3a8691d8f94b43cd4dd533186f20ccfa.nii.gz/MD5E-s10092523--3a8691d8f94b43cd4dd533186f20ccfa.nii.gz\n",
      "  - ds003416/.git/annex/objects/Mg/PF/MD5E-s119373412--450f63fea7f108c7a66f9d8371283aa9.nii.gz/MD5E-s119373412--450f63fea7f108c7a66f9d8371283aa9.nii.gz\n",
      "  ... and 1129 more\n",
      "/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215_dwi.nii.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Running BeyondFA baseline on ds003416 prequal derivatives...\")\n",
    "\n",
    "subjects = get_subjects(dataset_root, output_dir, tmp_dir, subjects_to_process)\n",
    "dwi_files = find_dwi_files(subjects, dataset_root)\n",
    "print(dwi_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a3a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215_dwi.nii\n",
      "============================================================\n",
      "Using bval: ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215_dwi.bval\n",
      "Using bvec: ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215_dwi.bvec\n",
      "Creating mask, response, FODs, and peaks...\n",
      "  [CACHE] Mask already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/tractseg/nodif_brain_mask.nii.gz, skipping dwi2mask\n",
      "  Dataset has 56 gradient directions (sufficient for CSD)\n",
      "  [CACHE] Response already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/tractseg/response.txt, skipping dwi2response\n",
      "  [CACHE] FOD already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/tractseg/WM_FODs.nii.gz, skipping dwi2fod\n",
      "  [CACHE] Peaks already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/tractseg/peaks.nii.gz, skipping sh2peaks\n",
      "  [CACHE] TractSeg output already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/tractseg/bundle_segmentations, skipping TractSeg\n",
      "  [CACHE] All DTI metric files (FA, MD, AD, RD) already exist, skipping scil_dti_metrics\n",
      "Calculating average metrics in bundles...\n",
      "Running: mrthreshold /Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215_dwi.nii.gz -abs 0.4 /var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmp_md0g48f.nii.gz -force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  mrthreshold: [WARNING] existing output files will be overwritten\n",
      "  mrthreshold: uncompressing image \"/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215_dwi.nii.gz\"... [==================================================]\n",
      "  mrthreshold: [WARNING] requested datatype (Bit) not supported - substituting with UInt8\n",
      "  mrthreshold: Determining and applying per-volume thresholds... [==================================================]\n",
      "  mrthreshold: compressing image \"/var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmp_md0g48f.nii.gz\"... [==================================================]\n",
      "  mrconvert: [WARNING] existing output files will be overwritten\n",
      "  mrconvert: uncompressing image \"/var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmp_md0g48f.nii.gz\"... [==================================================]\n",
      "  mrconvert: copying from \"/var/folde...0000gn/T/tmp_md0g48f.nii.gz\" to \"/Users/maa...run-215/fodf/wm_mask.nii.gz\"... [==================================================]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: mrconvert /var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmp_md0g48f.nii.gz /Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/fodf/wm_mask.nii.gz -datatype uint8 -force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  mrconvert: compressing image \"/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/fodf/wm_mask.nii.gz\"... [==================================================]\n",
      "  mrthreshold: [WARNING] existing output files will be overwritten\n",
      "  mrthreshold: uncompressing image \"/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216_dwi.nii.gz\"... [==================================================]\n",
      "  mrthreshold: [WARNING] requested datatype (Bit) not supported - substituting with UInt8\n",
      "  mrthreshold: Determining and applying per-volume thresholds... [==================================================]\n",
      "  mrthreshold: compressing image \"/var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpsm21g4cs.nii.gz\"... [==================================================]\n",
      "  mrconvert: [WARNING] existing output files will be overwritten\n",
      "  mrconvert: uncompressing image \"/var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpsm21g4cs.nii.gz\"... [==================================================]\n",
      "  mrconvert: copying from \"/var/folde...0000gn/T/tmpsm21g4cs.nii.gz\" to \"/Users/maa...run-216/fodf/wm_mask.nii.gz\"... [==================================================]\n",
      "  mrconvert: compressing image \"/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216/fodf/wm_mask.nii.gz\"... [==================================================]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [CACHE] Fiber response function already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/fodf/frf.txt, skipping estimate_frf\n",
      "  [CACHE] fODF already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/fodf/fodf.nii.gz, skipping computation\n",
      "  [CACHE] FODF metrics already exist: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/metric/afd_total.nii.gz, tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/metric/nufo.nii.gz, skipping extract_fodf_metrics\n",
      "  [CACHE] Tensor metrics files already exist, skipping fslstats calculations\n",
      "Extracting and combining all metrics to tmp/tractseg_fa_output...\n",
      "Extracted 432 values (combined metrics) saved to tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215/combined_metrics.json\n",
      "All metrics saved to output/sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215_features-None.json!\n",
      "Processing complete for sub-cIVs082_ses-s1Bx2_acq-b2000n56r21x21x22peAPP_run-215!\n",
      "\n",
      "============================================================\n",
      "Processing: sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216_dwi.nii\n",
      "============================================================\n",
      "Using bval: ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216_dwi.bval\n",
      "Using bvec: ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216_dwi.bvec\n",
      "Creating mask, response, FODs, and peaks...\n",
      "  [CACHE] Mask already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216/tractseg/nodif_brain_mask.nii.gz, skipping dwi2mask\n",
      "  WARNING: Dataset has only 3 gradient directions\n",
      "  CSD requires at least 6 directions. Skipping CSD/FOD/peaks/TractSeg steps.\n",
      "  Will only calculate DTI metrics (FA) for this dataset.\n",
      "  Skipping dwi2response (insufficient directions)\n",
      "  Skipping dwi2fod (insufficient directions)\n",
      "  Skipping sh2peaks (insufficient directions)\n",
      "  Skipping TractSeg (insufficient directions for CSD/FOD)\n",
      "  [CACHE] All DTI metric files (FA, MD, AD, RD) already exist, skipping scil_dti_metrics\n",
      "Calculating average metrics in bundles...\n",
      "  Skipping bundle metrics calculation (TractSeg was skipped due to insufficient directions)\n",
      "Running: mrthreshold /Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216_dwi.nii.gz -abs 0.4 /var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpsm21g4cs.nii.gz -force\n",
      "Running: mrconvert /var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpsm21g4cs.nii.gz /Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216/fodf/wm_mask.nii.gz -datatype uint8 -force\n",
      "  [CACHE] Fiber response function already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216/fodf/frf.txt, skipping estimate_frf\n",
      "  [CACHE] fODF already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216/fodf/fodf.nii.gz, skipping computation\n",
      "  [CACHE] FODF metrics already exist: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216/metric/afd_total.nii.gz, tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216/metric/nufo.nii.gz, skipping extract_fodf_metrics\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for fa.\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for md.\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for ad.\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for rd.\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for afd_total.\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for nufo.\n",
      "Extracting and combining all metrics to tmp/tractseg_fa_output...\n",
      "Extracted 432 values (combined metrics) saved to tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216/combined_metrics.json\n",
      "All metrics saved to output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216_features-None.json!\n",
      "Processing complete for sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-216!\n",
      "\n",
      "============================================================\n",
      "Processing: sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217_dwi.nii\n",
      "============================================================\n",
      "Using bval: ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217_dwi.bval\n",
      "Using bvec: ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217_dwi.bvec\n",
      "Creating mask, response, FODs, and peaks...\n",
      "  [CACHE] Mask already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/tractseg/nodif_brain_mask.nii.gz, skipping dwi2mask\n",
      "  Dataset has 40 gradient directions (sufficient for CSD)\n",
      "  [CACHE] Response already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/tractseg/response.txt, skipping dwi2response\n",
      "  [CACHE] FOD already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/tractseg/WM_FODs.nii.gz, skipping dwi2fod\n",
      "  [CACHE] Peaks already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/tractseg/peaks.nii.gz, skipping sh2peaks\n",
      "  [CACHE] TractSeg output already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/tractseg/bundle_segmentations, skipping TractSeg\n",
      "  [CACHE] All DTI metric files (FA, MD, AD, RD) already exist, skipping scil_dti_metrics\n",
      "Calculating average metrics in bundles...\n",
      "Running: mrthreshold /Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217_dwi.nii.gz -abs 0.4 /var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpcwoyswur.nii.gz -force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  mrthreshold: [WARNING] existing output files will be overwritten\n",
      "  mrthreshold: uncompressing image \"/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217_dwi.nii.gz\"... [==================================================]\n",
      "  mrthreshold: [WARNING] requested datatype (Bit) not supported - substituting with UInt8\n",
      "  mrthreshold: Determining and applying per-volume thresholds... [==================================================]\n",
      "  mrthreshold: compressing image \"/var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpcwoyswur.nii.gz\"... [==================================================]\n",
      "  mrconvert: [WARNING] existing output files will be overwritten\n",
      "  mrconvert: uncompressing image \"/var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpcwoyswur.nii.gz\"... [==================================================]\n",
      "  mrconvert: copying from \"/var/folde...0000gn/T/tmpcwoyswur.nii.gz\" to \"/Users/maa...run-217/fodf/wm_mask.nii.gz\"... [==================================================]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: mrconvert /var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpcwoyswur.nii.gz /Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/fodf/wm_mask.nii.gz -datatype uint8 -force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  mrconvert: compressing image \"/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/fodf/wm_mask.nii.gz\"... [==================================================]\n",
      "  mrthreshold: [WARNING] existing output files will be overwritten\n",
      "  mrthreshold: uncompressing image \"/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113_dwi.nii.gz\"... [==================================================]\n",
      "  mrthreshold: [WARNING] requested datatype (Bit) not supported - substituting with UInt8\n",
      "  mrthreshold: Determining and applying per-volume thresholds... [==================================================]\n",
      "  mrthreshold: compressing image \"/var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpirp4oxzi.nii.gz\"... [==================================================]\n",
      "  mrconvert: [WARNING] existing output files will be overwritten\n",
      "  mrconvert: uncompressing image \"/var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpirp4oxzi.nii.gz\"... [==================================================]\n",
      "  mrconvert: copying from \"/var/folde...0000gn/T/tmpirp4oxzi.nii.gz\" to \"/Users/maa...run-113/fodf/wm_mask.nii.gz\"... [==================================================]\n",
      "  mrconvert: compressing image \"/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113/fodf/wm_mask.nii.gz\"... [==================================================]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [CACHE] Fiber response function already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/fodf/frf.txt, skipping estimate_frf\n",
      "  [CACHE] fODF already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/fodf/fodf.nii.gz, skipping computation\n",
      "  [CACHE] FODF metrics already exist: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/metric/afd_total.nii.gz, tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/metric/nufo.nii.gz, skipping extract_fodf_metrics\n",
      "  [CACHE] Tensor metrics files already exist, skipping fslstats calculations\n",
      "Extracting and combining all metrics to tmp/tractseg_fa_output...\n",
      "Extracted 432 values (combined metrics) saved to tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217/combined_metrics.json\n",
      "All metrics saved to output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217_features-None.json!\n",
      "Processing complete for sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-217!\n",
      "\n",
      "============================================================\n",
      "Processing: sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113_dwi.nii\n",
      "============================================================\n",
      "Using bval: ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113_dwi.bval\n",
      "Using bvec: ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113_dwi.bvec\n",
      "Creating mask, response, FODs, and peaks...\n",
      "  [CACHE] Mask already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113/tractseg/nodif_brain_mask.nii.gz, skipping dwi2mask\n",
      "  WARNING: Dataset has only 3 gradient directions\n",
      "  CSD requires at least 6 directions. Skipping CSD/FOD/peaks/TractSeg steps.\n",
      "  Will only calculate DTI metrics (FA) for this dataset.\n",
      "  Skipping dwi2response (insufficient directions)\n",
      "  Skipping dwi2fod (insufficient directions)\n",
      "  Skipping sh2peaks (insufficient directions)\n",
      "  Skipping TractSeg (insufficient directions for CSD/FOD)\n",
      "  [CACHE] All DTI metric files (FA, MD, AD, RD) already exist, skipping scil_dti_metrics\n",
      "Calculating average metrics in bundles...\n",
      "  Skipping bundle metrics calculation (TractSeg was skipped due to insufficient directions)\n",
      "Running: mrthreshold /Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113_dwi.nii.gz -abs 0.4 /var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpirp4oxzi.nii.gz -force\n",
      "Running: mrconvert /var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpirp4oxzi.nii.gz /Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113/fodf/wm_mask.nii.gz -datatype uint8 -force\n",
      "  [CACHE] Fiber response function already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113/fodf/frf.txt, skipping estimate_frf\n",
      "  [CACHE] fODF already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113/fodf/fodf.nii.gz, skipping computation\n",
      "  [CACHE] FODF metrics already exist: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113/metric/afd_total.nii.gz, tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113/metric/nufo.nii.gz, skipping extract_fodf_metrics\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for fa.\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for md.\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for ad.\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for rd.\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for afd_total.\n",
      "  No bundle ROIs found. Creating empty tensor metrics file for nufo.\n",
      "Extracting and combining all metrics to tmp/tractseg_fa_output...\n",
      "Extracted 432 values (combined metrics) saved to tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113/combined_metrics.json\n",
      "All metrics saved to output/sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113_features-None.json!\n",
      "Processing complete for sub-cIVs082_ses-s1Bx2_acq-b1000n3r21x21x22peAPA_run-113!\n",
      "\n",
      "============================================================\n",
      "Processing: sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114_dwi.nii\n",
      "============================================================\n",
      "Using bval: ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114_dwi.bval\n",
      "Using bvec: ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114_dwi.bvec\n",
      "Creating mask, response, FODs, and peaks...\n",
      "  [CACHE] Mask already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114/tractseg/nodif_brain_mask.nii.gz, skipping dwi2mask\n",
      "  Dataset has 40 gradient directions (sufficient for CSD)\n",
      "  [CACHE] Response already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114/tractseg/response.txt, skipping dwi2response\n",
      "  [CACHE] FOD already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114/tractseg/WM_FODs.nii.gz, skipping dwi2fod\n",
      "  [CACHE] Peaks already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114/tractseg/peaks.nii.gz, skipping sh2peaks\n",
      "  [CACHE] TractSeg output already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114/tractseg/bundle_segmentations, skipping TractSeg\n",
      "  [CACHE] All DTI metric files (FA, MD, AD, RD) already exist, skipping scil_dti_metrics\n",
      "Calculating average metrics in bundles...\n",
      "Running: mrthreshold /Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114_dwi.nii.gz -abs 0.4 /var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpntapd8mu.nii.gz -force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  mrthreshold: [WARNING] existing output files will be overwritten\n",
      "  mrthreshold: uncompressing image \"/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/ds003416/derivatives/prequal-v1.0.0/sub-cIVs082/ses-s1Bx2/dwi/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114_dwi.nii.gz\"... [==================================================]\n",
      "  mrthreshold: [WARNING] requested datatype (Bit) not supported - substituting with UInt8\n",
      "  mrthreshold: Determining and applying per-volume thresholds... [==================================================]\n",
      "  mrthreshold: compressing image \"/var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpntapd8mu.nii.gz\"... [==================================================]\n",
      "  mrconvert: [WARNING] existing output files will be overwritten\n",
      "  mrconvert: uncompressing image \"/var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpntapd8mu.nii.gz\"... [==================================================]\n",
      "  mrconvert: copying from \"/var/folde...0000gn/T/tmpntapd8mu.nii.gz\" to \"/Users/maa...run-114/fodf/wm_mask.nii.gz\"... [==================================================]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: mrconvert /var/folders/5z/rgx8sdx575v6n3c32wj0dj5c0000gn/T/tmpntapd8mu.nii.gz /Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114/fodf/wm_mask.nii.gz -datatype uint8 -force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  mrconvert: compressing image \"/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114/fodf/wm_mask.nii.gz\"... [==================================================]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [CACHE] Fiber response function already exists: tmp/tractseg_fa_output/sub-cIVs082_ses-s1Bx2_acq-b1000n40r21x21x22peAPP_run-114/fodf/frf.txt, skipping estimate_frf\n",
      "Computing fODF from ds003416/.git/annex/objects/Mg/PF/MD5E-s119373412--450f63fea7f108c7a66f9d8371283aa9.nii.gz/MD5E-s119373412--450f63fea7f108c7a66f9d8371283aa9.nii.gz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maahes/Documents/MAI/UB/DLMIA/BeyondFA/.venv/lib/python3.12/site-packages/dipy/testing/decorators.py:192: UserWarning: Number of parameters required for the fit are more than the actual data points\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting CSD model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# compute fodf\u001b[39;00m\n\u001b[32m    103\u001b[39m fodf_file = fodf_dir / \u001b[33m\"\u001b[39m\u001b[33mfodf.nii.gz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mcompute_fodf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdwi_nifti_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbval_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbvec_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfodf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# compute fodf metrics: AFD_total, NuFO\u001b[39;00m\n\u001b[32m    106\u001b[39m feature_size = extract_fodf_metrics(fa_dir, fodf_file, mask_file)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MAI/UB/DLMIA/BeyondFA/utils/fodf.py:97\u001b[39m, in \u001b[36mcompute_fodf\u001b[39m\u001b[34m(dwi_file, bval_file, bvec_file, frf_file, output_file, mask_file, sh_order)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Fit & compute fODF\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  Fitting CSD model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m csd_fit = \u001b[43mcsd_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  Computing fODF (spherical harmonics coefficients)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Get SH coefficients instead of ODF values (required for scil_fodf_metrics.py)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MAI/UB/DLMIA/BeyondFA/.venv/lib/python3.12/site-packages/dipy/reconst/multi_voxel.py:85\u001b[39m, in \u001b[36mmulti_voxel_fit.<locals>.new_fit\u001b[39m\u001b[34m(self, data, mask, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_is_array:\n\u001b[32m     83\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m] = weights[ijk]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m svf = \u001b[43msingle_voxel_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mijk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Not all fit methods return extra, handle this here\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(svf, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MAI/UB/DLMIA/BeyondFA/.venv/lib/python3.12/site-packages/dipy/reconst/csdeconv.py:196\u001b[39m, in \u001b[36mConstrainedSphericalDeconvModel.fit\u001b[39m\u001b[34m(self, data, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;129m@multi_voxel_fit\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, **kwargs):\n\u001b[32m    195\u001b[39m     dwi_data = data[\u001b[38;5;28mself\u001b[39m._where_dwi]\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     shm_coeff, _ = \u001b[43mcsdeconv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdwi_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mB_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvergence\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvergence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mP\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SphHarmFit(\u001b[38;5;28mself\u001b[39m, shm_coeff, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MAI/UB/DLMIA/BeyondFA/.venv/lib/python3.12/site-packages/dipy/testing/decorators.py:196\u001b[39m, in \u001b[36mwarning_for_keywords.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# Check if the current version is within the warning range\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[43mversion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m     <= version.parse(current_version)\n\u001b[32m    198\u001b[39m     <= version.parse(until_version)\n\u001b[32m    199\u001b[39m ):\n\u001b[32m    200\u001b[39m     \u001b[38;5;66;03m# Convert positional to keyword arguments and issue a warning\u001b[39;00m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_positional_to_keyword(func, args, kwargs)\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# If the version is greater than the until_version,\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# pass the arguments as they are\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MAI/UB/DLMIA/BeyondFA/.venv/lib/python3.12/site-packages/packaging/version.py:56\u001b[39m, in \u001b[36mparse\u001b[39m\u001b[34m(version)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(version: \u001b[38;5;28mstr\u001b[39m) -> Version:\n\u001b[32m     48\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the given version string.\u001b[39;00m\n\u001b[32m     49\u001b[39m \n\u001b[32m     50\u001b[39m \u001b[33;03m    >>> parse('1.0.dev1')\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[33;03m    :raises InvalidVersion: When the version string is not a valid version.\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVersion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MAI/UB/DLMIA/BeyondFA/.venv/lib/python3.12/site-packages/packaging/version.py:217\u001b[39m, in \u001b[36mVersion.__init__\u001b[39m\u001b[34m(self, version)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28mself\u001b[39m._version = _Version(\n\u001b[32m    206\u001b[39m     epoch=\u001b[38;5;28mint\u001b[39m(match.group(\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m match.group(\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m,\n\u001b[32m    207\u001b[39m     release=\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m match.group(\u001b[33m\"\u001b[39m\u001b[33mrelease\u001b[39m\u001b[33m\"\u001b[39m).split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m   (...)\u001b[39m\u001b[32m    213\u001b[39m     local=_parse_local_version(match.group(\u001b[33m\"\u001b[39m\u001b[33mlocal\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m    214\u001b[39m )\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# Generate a key which will be used for sorting\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m \u001b[38;5;28mself\u001b[39m._key = \u001b[43m_cmpkey\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_version\u001b[49m\u001b[43m.\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_version\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelease\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_version\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_version\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_version\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_version\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MAI/UB/DLMIA/BeyondFA/.venv/lib/python3.12/site-packages/packaging/version.py:523\u001b[39m, in \u001b[36m_cmpkey\u001b[39m\u001b[34m(epoch, release, pre, post, dev, local)\u001b[39m\n\u001b[32m    516\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m    517\u001b[39m             part.lower() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m part.isdigit() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(part)\n\u001b[32m    518\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m _local_version_separators.split(local)\n\u001b[32m    519\u001b[39m         )\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cmpkey\u001b[39m(\n\u001b[32m    524\u001b[39m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    525\u001b[39m     release: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, ...],\n\u001b[32m    526\u001b[39m     pre: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    527\u001b[39m     post: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    528\u001b[39m     dev: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    529\u001b[39m     local: LocalType | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    530\u001b[39m ) -> CmpKey:\n\u001b[32m    531\u001b[39m     \u001b[38;5;66;03m# When we compare a release version, we want to compare it with all of the\u001b[39;00m\n\u001b[32m    532\u001b[39m     \u001b[38;5;66;03m# trailing zeros removed. So we'll use a reverse the list, drop all the now\u001b[39;00m\n\u001b[32m    533\u001b[39m     \u001b[38;5;66;03m# leading zeros until we come to something non zero, then take the rest\u001b[39;00m\n\u001b[32m    534\u001b[39m     \u001b[38;5;66;03m# re-reverse it back into the correct order and make it a tuple and use\u001b[39;00m\n\u001b[32m    535\u001b[39m     \u001b[38;5;66;03m# that for our sorting key.\u001b[39;00m\n\u001b[32m    536\u001b[39m     _release = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m    537\u001b[39m         \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(itertools.dropwhile(\u001b[38;5;28;01mlambda\u001b[39;00m x: x == \u001b[32m0\u001b[39m, \u001b[38;5;28mreversed\u001b[39m(release))))\n\u001b[32m    538\u001b[39m     )\n\u001b[32m    540\u001b[39m     \u001b[38;5;66;03m# We need to \"trick\" the sorting algorithm to put 1.0.dev0 before 1.0a0.\u001b[39;00m\n\u001b[32m    541\u001b[39m     \u001b[38;5;66;03m# We'll do this by abusing the pre segment, but we _only_ want to do this\u001b[39;00m\n\u001b[32m    542\u001b[39m     \u001b[38;5;66;03m# if there is not a pre or a post segment. If we have one of those then\u001b[39;00m\n\u001b[32m    543\u001b[39m     \u001b[38;5;66;03m# the normal sorting rules will handle this case correctly.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Process each DWI file\n",
    "for dwi_nifti_file in dwi_files:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {dwi_nifti_file.stem}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Find corresponding bval and bvec files (BIDS naming convention)\n",
    "    # They should have the same base name as the nifti file\n",
    "    base_name = dwi_nifti_file.stem.replace('.nii', '')  # Remove .nii from .nii.gz\n",
    "    bval_path = dwi_nifti_file.parent / f\"{relative(base_name)}.bval\"\n",
    "    bvec_path = dwi_nifti_file.parent / f\"{relative(base_name)}.bvec\"\n",
    "    \n",
    "    # Verify bval and bvec files exist\n",
    "    if not bval_path.exists():\n",
    "        print(f\"Warning: bval file not found: {relative(bval_path)}, skipping...\")\n",
    "        continue\n",
    "    if not bvec_path.exists():\n",
    "        print(f\"Warning: bvec file not found: {relative(bvec_path)}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Using bval: {relative(bval_path)}\")\n",
    "    print(f\"Using bvec: {relative(bvec_path)}\")\n",
    "    \n",
    "    # Create a unique identifier for this file (subject_session_run)\n",
    "    # Extract from path: sub-*/ses-*/dwi/*_dwi.nii.gz\n",
    "    parts = dwi_nifti_file.parts\n",
    "    subject = [p for p in parts if p.startswith(\"sub-\")][0]\n",
    "    session = [p for p in parts if p.startswith(\"ses-\")][0]\n",
    "    run_info = base_name.replace(f\"{subject}_{session}_\", \"\").replace(\"_dwi\", \"\")\n",
    "    file_id = f\"{subject}_{session}_{run_info}\"\n",
    "    \n",
    "    # Create directories\n",
    "    tractseg_dir = tractseg_output_dir / file_id / \"tractseg\"\n",
    "    tractseg_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "\n",
    "    print(\"Creating mask, response, FODs, and peaks...\")\n",
    "    \n",
    "    # Create mask\n",
    "    mask_file = tractseg_dir / \"nodif_brain_mask.nii.gz\"\n",
    "    create_mask(dwi_nifti_file, mask_file, bvec_path, bval_path)\n",
    "    \n",
    "    # Check number of gradient directions before proceeding with CSD\n",
    "    # Read bval file to count non-zero b-values (gradient directions)\n",
    "    with open(bval_path, 'r') as f:\n",
    "        bvals = [float(x) for x in f.read().strip().split()]\n",
    "    \n",
    "    num_gradient_directions = sum(1 for bval in bvals if bval > 0)\n",
    "    min_directions_for_csd = 6  # CSD requires at least 6 directions for lmax=2\n",
    "    \n",
    "    if num_gradient_directions < min_directions_for_csd:\n",
    "        print(f\"  WARNING: Dataset has only {num_gradient_directions} gradient directions\")\n",
    "        print(f\"  CSD requires at least {min_directions_for_csd} directions. Skipping CSD/FOD/peaks/TractSeg steps.\")\n",
    "        print(f\"  Will only calculate DTI metrics (FA) for this dataset.\")\n",
    "        skip_csd = True\n",
    "    else:\n",
    "        print(f\"  Dataset has {num_gradient_directions} gradient directions (sufficient for CSD)\")\n",
    "        skip_csd = False\n",
    "    \n",
    "    # Create response\n",
    "    response_file = tractseg_dir / \"response.txt\"\n",
    "    create_response(dwi_nifti_file, response_file, bvec_path, bval_path, skip_csd)\n",
    "    \n",
    "    # Create FODs\n",
    "    fod_file = tractseg_dir / \"WM_FODs.nii.gz\"\n",
    "    create_fod(dwi_nifti_file, fod_file, response_file, bvec_path, bval_path, skip_csd)\n",
    "    \n",
    "    # Create peaks\n",
    "    peaks_file = tractseg_dir / \"peaks.nii.gz\"\n",
    "    create_peaks(fod_file, peaks_file, mask_file, skip_csd)\n",
    "    \n",
    "    # Run TractSeg\n",
    "    # Check if TractSeg output exists (check for bundle_segmentations directory)\n",
    "    bundle_roi_dir = tractseg_dir / \"bundle_segmentations\"\n",
    "    run_tractseg(peaks_file, bundle_roi_dir, tractseg_dir, bval_path, bvec_path, mask_file, skip_csd)\n",
    "\n",
    "    # Run DTI metrics calculation \n",
    "    fa_dir = tractseg_output_dir / file_id / \"metric\"\n",
    "    fa_dir.mkdir(parents=True, exist_ok=True)\n",
    "    run_scilpy_dti(fa_dir, dwi_nifti_file, mask_file, bval_path, bvec_path)\n",
    "    \n",
    "    # Get corresponding metrics for all 4 metrics: FA, MD, AD, RD\n",
    "    print(\"Calculating average metrics in bundles...\")\n",
    "    # bundle_roi_dir already defined above for caching check\n",
    "    \n",
    "    # Make json with mean of metrics in bundle\n",
    "    if skip_csd or not bundle_roi_dir.exists():\n",
    "        print(f\"  Skipping bundle metrics calculation (TractSeg was skipped due to insufficient directions)\")\n",
    "        roi_list = []\n",
    "    else:\n",
    "        roi_list = sorted(bundle_roi_dir.glob(\"*.nii.gz\"))\n",
    "\n",
    "    # fodf metric pipeline\n",
    "    fodf_dir = tractseg_output_dir / file_id / \"fodf\"\n",
    "    fodf_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # create white matter mask\n",
    "    wm_mask_file = fodf_dir / \"wm_mask.nii.gz\"\n",
    "    create_white_matter_mask(dwi_nifti_file, wm_mask_file)\n",
    "    # estimate fiber response function\n",
    "    frf_file = fodf_dir / \"frf.txt\"\n",
    "    estimate_frf(dwi_nifti_file, mask_file, wm_mask_file, frf_file, bval_path, bvec_path)\n",
    "    # compute fodf\n",
    "    fodf_file = fodf_dir / \"fodf.nii.gz\"\n",
    "    compute_fodf(dwi_nifti_file, bval_path, bvec_path, frf_file, fodf_file, mask_file)\n",
    "    # compute fodf metrics: AFD_total, NuFO\n",
    "    extract_fodf_metrics(fa_dir, fodf_file, mask_file)\n",
    "\n",
    "    # Create tensor metrics files for each metric\n",
    "    metrics = ['fa', 'md', 'ad', 'rd', 'afd_total', 'nufo']\n",
    "    tensor_metrics_files = bundle_metrics(fa_dir, roi_list, tractseg_output_dir, file_id, metrics)\n",
    "    \n",
    "    # Extract all metrics and combine into 512-element vector\n",
    "    print(f\"Extracting and combining all metrics to {relative(tractseg_output_dir)}...\")\n",
    "    \n",
    "    # Check if final output already exists\n",
    "    feature_size = 72 * len(metrics)\n",
    "    output_name = output_dir / f\"{file_id}_features-{feature_size}.json\"\n",
    "    if output_name.exists():\n",
    "        print(f\"  [CACHE] Final output already exists: {relative(output_name)}, skipping extraction\")\n",
    "    else:\n",
    "        # Prepare metric files dictionary\n",
    "        metric_files_dict = {}\n",
    "        for metric in metrics:\n",
    "            if tensor_metrics_files[metric].exists():\n",
    "                metric_files_dict[metric] = str(tensor_metrics_files[metric])\n",
    "        \n",
    "        # Combine all metrics into a vector\n",
    "        combined_json_file = tractseg_output_dir / file_id / \"combined_metrics.json\"\n",
    "        extract_multiple_metrics(metric_files_dict, str(combined_json_file), metrics)\n",
    "        \n",
    "        # Save the final metric.json to output directory with unique name\n",
    "        print(f\"All metrics saved to {relative(output_name)}!\")\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        combined_json_file.replace(output_name)\n",
    "    \n",
    "    print(f\"Processing complete for {file_id}!\")\n",
    "\n",
    "print(f\"All completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
